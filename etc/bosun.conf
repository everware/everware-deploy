tsdbHost = localhost:4242
stateFile = /data/bosun.state
ledisBindAddr = 0.0.0.0:9565
smtpHost = mx.yandex-team.ru:25
emailFrom = bosun@everware.xyz


template test {
	subject = {{.Last.Status}}: {{.Alert.Name}} on {{.Group.host}}
	body = `<p>Alert: {{.Alert.Name}} triggered on {{.Group.host}}
	<hr>
	<p><strong>Computation</strong>
	<table>
		{{range .Computations}}
			<tr><td><a href="{{$.Expr .Text}}">{{.Text}}</a></td><td>{{.Value}}</td></tr>
		{{end}}
	</table>
	<hr>
	{{ .Graph .Alert.Vars.metric }}
	<hr>
	<p><strong>Relevant Tags</strong>
	<table>
		{{range $k, $v := .Group}}
			<tr><td>{{$k}}</td><td>{{$v}}</td></tr>
		{{end}}
	</table>`
}


# email sysadmins and Nick each day until ack'd
notification default {
	email = anaderi@yandex-team.ru
	next = default
	timeout = 1d
}

alert cpu.is.too.high {
    warnNotification = default
    template = test
    $metric = q("sum:rate{counter,,1}:os.cpu{host=*}", "1h", "")
    $avgcpu = avg($metric)
    crit = $avgcpu > 80
    warn = $avgcpu > 50
}

alert sockets.is.too.high {
    warnNotification = default
    template = test
    $metric = q("sum:linux.net.sockets.used{host=*}", "1h", "")
    $avgtime = avg($metric)
    crit = $avgtime > 30000
    warn = $avgtime > 10000
}

alert docker.containers.active.dev.high {
    warnNotification = default
    template = test
    $metric = q("dev:3m-avg:docker.contatiners.active", "1h", "")
    $maxdev = max($metric)
    warn = $maxdev > 2
    crit = $maxdev > 3
}

alert docker.containers.more.than.cpus {
    warnNotification = default
    template = test
    $metric = q("max:docker.contatiners.active{host=*}", "30m", "")
    $containers_hosts = max($metric)
    warn = $containers_hosts > 12
    crit = $containers_hosts > 16
}

alert disk.free.space.too.low {
    warnNotification = default
    template = test
    $metric = q("min:os.disk.fs.percent_free{host=*}", "1h", "")
    $containers_hosts = min($metric)
    warn = $containers_hosts < 50
    crit = $containers_hosts < 10
}

alert mem.free.too.low {
    warnNotification = default
    template = test
    $metric = q("min:os.mem.percent_free{host=*}", "10m", "")
    $containers_hosts = min($metric)
    warn = $containers_hosts < 10
    crit = $containers_hosts < 5
}

alert traffic.in.is.too.high {
    warnNotification = default
    template = test
    $metric = q("sum:rate:linux.net.stat.ip.inoctets{host=*}", "1h", "")
    $avgcpu = max($metric)
    crit = $avgcpu > 200000000
    warn = $avgcpu > 10000000
}

alert traffic.out.is.too.high {
    warnNotification = default
    template = test
    $metric = q("sum:rate:linux.net.stat.ip.outoctets{host=*}", "1h", "")
    $avgcpu = max($metric)
    crit = $avgcpu > 200000000
    warn = $avgcpu > 10000000
}

